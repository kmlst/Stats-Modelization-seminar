{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley value computation\n",
    "\n",
    "We consider a monte carlo (or quasi-monte carlo) estimation technique before jumping to the discrete uniforme shapley value as proposed by the article.\n",
    "\n",
    "We imagine a scenario where k players each have some data and need to pool it to collaborate on tasks :\n",
    "\n",
    "1 - MNIST digit classification with a twist : some of the data is noisy and not all players have thus the same quality or quantity of data.\n",
    "\n",
    "2 - An XGBoost regressor : the data is squeaky clean and well adjusted for each. The goal is to compare the featue importances with those already implemented in XGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature shap_importance\n",
      "1  Feature2        2.975537\n",
      "0  Feature1        0.516939\n",
      "2  Feature3        0.379312\n",
      "['Feature2', 'Feature1', 'Feature3']\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'Feature1': np.random.normal(loc=0, scale=1, size=100),\n",
    "    'Feature2': np.random.normal(loc=2, scale=1.5, size=100),\n",
    "    'Feature3': np.random.uniform(low=-1, high=1, size=100)\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Generate a target variable with some dependency\n",
    "df['Target'] = df['Feature1'] * 0.5 + df['Feature2'] * 1.5 + np.random.normal(loc=0, scale=1, size=100)\n",
    "\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# transform the target to category by binning\n",
    "y = pd.qcut(y, q=2, labels=False)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = XGBClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Create the explainer and SHAP values\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X_train)\n",
    "\n",
    "# Calculate mean absolute SHAP values for each feature\n",
    "shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "importance_df = pd.DataFrame([X_train.columns.tolist(), shap_sum.tolist()]).T\n",
    "importance_df.columns = ['feature', 'shap_importance']\n",
    "\n",
    "# Sort features by importance\n",
    "importance_df = importance_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# Select top features (here there are only 3)\n",
    "selected_features = importance_df.head(10)['feature'].tolist()\n",
    "\n",
    "# show the results\n",
    "print(importance_df)\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from utils import DU_mnist_ShapleyCalculator, run_experiment, add_noise, apply_blur, occlude_data, downsample_data, mislabel_data\n",
    "\n",
    "# --- Configuration des scénarios et exécution des expériences ---\n",
    "\n",
    "scenarios = {\n",
    "    \"noise\": [0.1, 0.2, 0.3],\n",
    "    \"blur\": [3, 5, 7],\n",
    "    \"occlusion\": [0.1, 0.2, 0.3],\n",
    "    \"downsampling\": [2, 3, 4],\n",
    "    \"mislabeling\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "num_players = [5, 10]  # Nombre de joueurs à tester\n",
    "\n",
    "all_results = []\n",
    "for I in num_players:\n",
    "    for degradation_type, levels in scenarios.items():\n",
    "        for level in levels:\n",
    "            results = run_experiment(I, degradation_type, level)\n",
    "            all_results.append(results)\n",
    "\n",
    "# --- Analyse et visualisation des résultats ---\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for r in all_results:\n",
    "    for i in range(r['I']):\n",
    "        for rep in range(len(r['DU-Shapley'])):  # Parcourir les répétitions\n",
    "            df = df.append({'DU-Shapley': r['DU-Shapley'][rep][i],\n",
    "                            'True Shapley': r['True Shapley'][rep][i],\n",
    "                            'degradation_type': r['degradation_type'],\n",
    "                            'degradation_level': r['degradation_level'],\n",
    "                            'I': r['I'],\n",
    "                            'Player': i + 1,\n",
    "                            'Repetition': rep + 1}, ignore_index=True)\n",
    "\n",
    "# 1. Comparaison des distributions de DU-Shapley et True Shapley\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='degradation_type', y='DU-Shapley', hue='degradation_level', data=df)\n",
    "plt.title(\"Distribution de DU-Shapley par type et niveau de dégradation\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='degradation_type', y='True Shapley', hue='degradation_level', data=df)\n",
    "plt.title(\"Distribution de la vraie valeur de Shapley par type et niveau de dégradation\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Analyse du biais de DU-Shapley\n",
    "df['Difference'] = df['DU-Shapley'] - df['True Shapley']\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='degradation_type', y='Difference', hue='degradation_level', data=df)\n",
    "plt.title(\"Biais de DU-Shapley (DU-Shapley - True Shapley) par type et niveau de dégradation\")\n",
    "plt.axhline(y=0, color='r', linestyle='--')  # Ligne de référence pour un biais nul\n",
    "plt.show()\n",
    "\n",
    "# 3. Calcul de la corrélation\n",
    "for degradation_type in scenarios.keys():\n",
    "    for level in scenarios[degradation_type]:\n",
    "        for I in num_players:\n",
    "            subset = df[(df['degradation_type'] == degradation_type) & (df['degradation_level'] == level) & (df['I'] == I)]\n",
    "            correlation = subset['DU-Shapley'].corr(subset['True Shapley'])\n",
    "            print(f\"Corrélation entre DU-Shapley et True Shapley ({degradation_type}, niveau {level}, I={I}): {correlation:.3f}\")\n",
    "\n",
    "# 4. Visualisation des résultats (exemple: impact du nombre de joueurs)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='I', y='Difference', hue='degradation_type', data=df)\n",
    "plt.title(\"Biais de DU-Shapley en fonction du nombre de joueurs\")\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# --- Tests statistiques ---\n",
    "\n",
    "# 1. Test t pour comparer DU-Shapley et True Shapley pour chaque scénario\n",
    "for degradation_type in scenarios.keys():\n",
    "    for level in scenarios[degradation_type]:\n",
    "        for I in num_players:\n",
    "            subset = df[(df['degradation_type'] == degradation_type) & (df['degradation_level'] == level) & (df['I'] == I)]\n",
    "            t_statistic, p_value = stats.ttest_rel(subset['DU-Shapley'], subset['True Shapley'])\n",
    "            print(f\"Test t pour {degradation_type}, niveau {level}, I={I}:\")\n",
    "            print(f\"  Statistique t: {t_statistic:.3f}\")\n",
    "            print(f\"  Valeur p: {p_value:.3f}\")\n",
    "\n",
    "# 2. ANOVA pour tester l'effet du niveau de dégradation sur le biais de DU-Shapley\n",
    "for degradation_type in scenarios.keys():\n",
    "    for I in num_players:\n",
    "        subset = df[(df['degradation_type'] == degradation_type) & (df['I'] == I)]\n",
    "        groups = subset['degradation_level'].unique()\n",
    "        f_statistic, p_value = stats.f_oneway(*[subset['Difference'][subset['degradation_level'] == g] for g in groups])\n",
    "        print(f\"ANOVA pour l'effet du niveau de {degradation_type} sur le biais, I={I}:\")\n",
    "        print(f\"  Statistique F: {f_statistic:.3f}\")\n",
    "        print(f\"  Valeur p: {p_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
